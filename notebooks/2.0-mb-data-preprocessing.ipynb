{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "supposed-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "import os  \n",
    "import pickle \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "powerful-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_path = os.path.join(os.path.abspath(os.path.join(os.path.abspath(os.curdir), os.pardir)), 'data', 'raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "realistic-watch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\data_analyst\\\\nova_ims\\\\dl\\\\dl_project\\\\data\\\\raw'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-stuart",
   "metadata": {},
   "source": [
    "Function that splits and merges all images into the respective train, validation or test tensors. Returns a list of tuple tensors. \n",
    "\n",
    "- img tensor dimensions: (num_images, 64, 64, 3) \n",
    "\n",
    "- labels tensor dimensions: (num_images, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "professional-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(src_path, size):  \n",
    "    \n",
    "    # start counters\n",
    "    num_img = 0 \n",
    "    train_count = 0 \n",
    "    val_count = 0 \n",
    "    test_count = 0\n",
    "    # save list of labels corresponding to each dir's name\n",
    "    labels = os.listdir(path=src_path) \n",
    "    labels.sort() \n",
    "    # go through each label/dir and add number of images inside to num_img\n",
    "    for i in labels: \n",
    "        num_img += len(os.listdir(path=os.path.join(src_path, i)))\n",
    "    \n",
    "    # initialize arrays filled with zeros corresponding to the output dimensions of the images and its labels for each split\n",
    "    X_train = np.zeros(shape=[int(num_img*0.6),size,size,3])\n",
    "    y_train = np.zeros(shape=[int(num_img*0.6),len(labels)])  \n",
    "    X_val = np.zeros(shape=[int(num_img*0.2),size,size,3])\n",
    "    y_val = np.zeros(shape=[int(num_img*0.2),len(labels)]) \n",
    "    X_test = np.zeros(shape=[int(num_img*0.2),size,size,3]) \n",
    "    y_test = np.zeros(shape=[int(num_img*0.2),len(labels)])\n",
    "    \n",
    "    # go through labels, save the path to its corresponding dir, and save the number of images inside\n",
    "    for index, label in enumerate(labels): \n",
    "        cur_path = os.path.join(src_path, label)  \n",
    "        n_img = len(os.listdir(path=cur_path))   \n",
    "\n",
    "        # open each image, convert into array, add data and labels to the corresponding split arrays\n",
    "        for i in range(1, n_img + 1):  \n",
    "            # fill train split when n_img has not reached 61% of the label\n",
    "            if i <= int(n_img * 0.6):\n",
    "                # keep track of index of the train arrays\n",
    "                train_count += 1\n",
    "                img = Image.open(os.path.join(cur_path, labels[index] + '_{}.jpg'.format(i))) \n",
    "                # convert image to array and rescale\n",
    "                img_arr = 1/255 * np.array(img)  \n",
    "                label_arr = np.zeros(len(labels)) \n",
    "                np.put(label_arr, index, 1)\n",
    "                X_train[train_count-1][:size][:size][:size] = img_arr  \n",
    "                y_train[train_count-1] = label_arr   \n",
    "                \n",
    "            # fill val split when n_img has not reached 81% of the label \n",
    "            elif i <= int(n_img * 0.8):  \n",
    "                # keep track of index of the val arrays\n",
    "                val_count += 1\n",
    "                img = Image.open(os.path.join(cur_path, labels[index] + '_{}.jpg'.format(i))) \n",
    "                # convert image to array and rescale\n",
    "                img_arr = 1/255 * np.array(img)  \n",
    "                label_arr = np.zeros(len(labels)) \n",
    "                np.put(label_arr, index, 1)\n",
    "                X_val[val_count-1][:size][:size][:size] = img_arr  \n",
    "                y_val[val_count-1] = label_arr \n",
    "                \n",
    "            # fill test split with remaining images of the label\n",
    "            else:  \n",
    "                # keep track of index of the test arrays\n",
    "                test_count += 1\n",
    "                img = Image.open(os.path.join(cur_path, labels[index] + '_{}.jpg'.format(i)))  \n",
    "                # convert image to array and rescale\n",
    "                img_arr = 1/255 * np.array(img)  \n",
    "                label_arr = np.zeros(len(labels)) \n",
    "                np.put(label_arr, index, 1)\n",
    "                X_test[test_count-1][:size][:size][:size] = img_arr  \n",
    "                y_test[test_count-1] = label_arr \n",
    "    \n",
    "    # return list of tensor tuples       \n",
    "    return [(X_train, y_train), (X_val, y_val), (X_test, y_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-mexico",
   "metadata": {},
   "source": [
    "Test function and load some data points for quality control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "divided-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_gen(dst_path, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a31e61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16200.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "27000 * 0.6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de0a0586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5400.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "27000 * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "southern-superintendent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16200, 64, 64, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fab6411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16200, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "annual-hearts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baf93e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][1][1800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0210997d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][1][3600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6081a2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71357dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 64, 64, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cb4aa81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ae204e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b89812ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1][1][600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "342511ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1][1][1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "404104de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1][1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c16488f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 64, 64, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d55e200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f6e5c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bddbd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2][1][600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49dc59be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2][1][1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb63598d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2][1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-township",
   "metadata": {},
   "source": [
    "Save and load data in pickle format for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "proper-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_train.pickle', 'wb') as f: \n",
    "    pickle.dump(data[0][0], f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "legitimate-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_train.pickle', 'wb') as f: \n",
    "    pickle.dump(data[0][1], f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "effective-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_train.pickle', 'rb') as f: \n",
    "    X_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5f4d745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16200, 64, 64, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e894feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_train.pickle', 'rb') as f: \n",
    "    y_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5300277f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16200, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
